{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32520e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/conda/envs/vlm_node_1016/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-11 07:39:43,612\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from conf.register_configs import register_configs\n",
    "from utils.factories import InferenceBootstrapper,SimWorkerFactory\n",
    "from utils.inference_core import run_inference_driver, create_shard_iterator\n",
    "import ray\n",
    "# Register our custom variants and resolvers\n",
    "register_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd487d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: Phyllis1/qwen3_sft_sft_sparse_03drop_single_action_20260103_210803_ckpt10800\n"
     ]
    }
   ],
   "source": [
    "# Initialize Hydra manually (replaces @hydra.main)\n",
    "# 'config_path' is relative to this notebook\n",
    "with initialize(version_base=None, config_path=\"conf\"):\n",
    "    # Here you can list overrides just like you would on the CLI\n",
    "    cfg = compose(config_name=\"inference_config\", overrides=[\n",
    "        \"task.run_name=test\",\n",
    "        \"rollout.max_steps=100\",\n",
    "        \"vlm.save_outputs=True\", # need this for RL\n",
    "        \n",
    "    ])\n",
    "\n",
    "print(f\"Model ID: {cfg.vlm.model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7220af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 07:39:51,722\tINFO worker.py:1998 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/root/conda/envs/vlm_node_1016/lib/python3.10/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bootstrapper = InferenceBootstrapper(cfg)\n",
    "bootstrapper.setup_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed7796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ref = SimWorkerFactory.create(bootstrapper.resolved_dict['sim'],bootstrapper.typed_cfg.resources,bootstrapper.typed_cfg.task,None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e784ed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m PluginManager::Manager: duplicate static plugin StbImageImporter, ignoring\n",
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m PluginManager::Manager: duplicate static plugin GltfImporter, ignoring\n",
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m PluginManager::Manager: duplicate static plugin BasisImporter, ignoring\n",
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m PluginManager::Manager: duplicate static plugin AssimpImporter, ignoring\n",
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m PluginManager::Manager: duplicate static plugin AnySceneImporter, ignoring\n",
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m PluginManager::Manager: duplicate static plugin AnyImageImporter, ignoring\n",
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m 2026-01-11 07:39:59,296 Initializing dataset ObjectNav-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m skipping sim initialization since no shards provided, please call assign_shard\n"
     ]
    }
   ],
   "source": [
    "ray.get(sim_ref.assign_shard.remote(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b8b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(HabitatRayWorker pid=2736680)\u001b[0m Actor assigned with shard of 2000 episodes.\n",
      "Loading Phyllis1/qwen3_sft_sft_sparse_03drop_single_action_20260103_210803_ckpt10800 with sparsifying patch...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PreTrainedModel.gradient_checkpointing_enable() got an unexpected keyword argument 'use_reentrant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m training_config \u001b[38;5;241m=\u001b[39m VLMTrainingConfig(peft_config\u001b[38;5;241m=\u001b[39mLoraConfig(\n\u001b[1;32m      5\u001b[0m                 r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, lora_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, lora_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAUSAL_LM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                 target_modules\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgate_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;66;03m# modules_to_save=[\"multi_modal_projector\"],\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                 modules_to_save\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial_head\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      9\u001b[0m     ))\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m RLWorker(bootstrapper\u001b[38;5;241m.\u001b[39mresolved_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrollout\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbootstrapper\u001b[38;5;241m.\u001b[39mresolved_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvlm\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m29500\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Projects/spatial_training/utils/vlm_worker.py:354\u001b[0m, in \u001b[0;36mVLMTrainingMixin.setup_training\u001b[0;34m(self, config, rank, world_size, master_addr, master_port)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# 3. Gradient Checkpointing (Must run before PEFT wrapping)\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mgradient_checkpointing:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_checkpointing_enable\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# This logic handles the edge case where input embeddings are frozen\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# causing backward() to fail with checkpointing enabled.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_input_require_grads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: PreTrainedModel.gradient_checkpointing_enable() got an unexpected keyword argument 'use_reentrant'"
     ]
    }
   ],
   "source": [
    "from utils.inference_core import InferenceWorker,RLWorker\n",
    "from utils.vlm_worker import VLMTrainingConfig\n",
    "from peft import LoraConfig\n",
    "training_config = VLMTrainingConfig(peft_config=LoraConfig(\n",
    "                r=128, lora_alpha=256, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\",\n",
    "                target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "                # modules_to_save=[\"multi_modal_projector\"],\n",
    "                modules_to_save=[\"spatial_head\"], \n",
    "    ))\n",
    "trainer = RLWorker(bootstrapper.resolved_dict['rollout'],**bootstrapper.resolved_dict['vlm'])\n",
    "trainer.setup_training(\n",
    "    config=training_config,\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    "    master_addr=\"localhost\",\n",
    "    master_port=29500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c630f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(HabitatRayWorker pid=2691174)\u001b[0m 2026-01-11 07:30:44,474 Video created: /Projects/spatial_training/dump/results/test/worker_0/6s7QHgap2fW/6s7QHgap2fW_61/video.mp4\n",
      "\u001b[36m(HabitatRayWorker pid=2691174)\u001b[0m IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (2626, 480) to (2640, 480) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "\u001b[36m(HabitatRayWorker pid=2691174)\u001b[0m [rawvideo @ 0x434891c0] Stream #0: not enough frames to estimate rate; consider increasing probesize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using normal mode\n",
      "keeping 300/300\n",
      "keeping 212/300\n",
      "keeping 238/300\n",
      "keeping 237/300\n",
      "keeping 226/300\n",
      "keeping 263/300\n",
      "keeping 30/300\n",
      "keeping 30/300\n",
      "keeping 30/300\n",
      "keeping 30/300\n",
      "keeping 223/300\n",
      "keeping 253/300\n",
      "keeping 268/300\n",
      "keeping 30/300\n",
      "keeping 205/300\n",
      "keeping 207/300\n",
      "keeping 222/300\n",
      "keeping 234/300\n",
      "keeping 210/300\n",
      "keeping 209/300\n",
      "keeping 215/300\n",
      "keeping 227/300\n",
      "keeping 224/300\n",
      "keeping 169/300\n",
      "keeping 207/300\n",
      "keeping 225/300\n",
      "keeping 249/300\n",
      "keeping 244/300\n",
      "keeping 232/300\n",
      "keeping 202/300\n",
      "keeping 238/300\n",
      "keeping 208/300\n",
      "keeping 208/300\n",
      "keeping 212/300\n",
      "keeping 214/300\n",
      "keeping 227/300\n",
      "keeping 241/300\n",
      "keeping 30/300\n",
      "keeping 30/300\n",
      "keeping 183/300\n",
      "keeping 219/300\n",
      "keeping 186/300\n",
      "keeping 30/300\n",
      "keeping 204/300\n",
      "keeping 186/300\n",
      "keeping 176/300\n",
      "keeping 234/300\n",
      "keeping 230/300\n",
      "keeping 217/300\n",
      "keeping 219/300\n",
      "keeping 228/300\n",
      "keeping 217/300\n",
      "keeping 194/300\n",
      "keeping 241/300\n",
      "keeping 241/300\n",
      "keeping 234/300\n",
      "keeping 268/300\n",
      "keeping 241/300\n",
      "keeping 212/300\n",
      "keeping 222/300\n",
      "keeping 193/300\n",
      "keeping 212/300\n",
      "keeping 225/300\n",
      "keeping 30/300\n",
      "keeping 176/300\n",
      "keeping 196/300\n",
      "keeping 185/300\n",
      "keeping 169/300\n",
      "keeping 160/300\n",
      "keeping 167/300\n",
      "keeping 197/300\n",
      "keeping 227/300\n",
      "keeping 198/300\n",
      "keeping 199/300\n",
      "keeping 198/300\n",
      "keeping 218/300\n",
      "keeping 194/300\n",
      "keeping 213/300\n",
      "keeping 185/300\n",
      "keeping 231/300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Actor(HabitatRayWorker, ae59e85d56bc6556cc6a02a701000000),\n",
       " False,\n",
       " {'episode_label': 'ziup5kvtCCR_43',\n",
       "  'spl': 0.42452780798895884,\n",
       "  'success': 1.0,\n",
       "  'steps': 80,\n",
       "  'goal_name': 'sofa'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run_episode(sim_ref,ray.get(sim_ref.reset.remote()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm_node_1016",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
